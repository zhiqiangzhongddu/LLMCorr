{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:29:18.597914Z",
     "start_time": "2024-01-08T19:29:18.571290Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import openai\n",
    "\n",
    "from code.config import cfg\n",
    "from code.query_chatgpt import num_tokens_from_messages, query_chatgpt_batch\n",
    "from code.utils import set_seed\n",
    "from code.data_utils.dataset import DatasetLoader\n",
    "from code.data_utils.utils import load_message, save_chatcompletion, save_response, clean_cache_chat_completion_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# load cfg\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "# manual cfg settings\n",
    "cfg.dataset = \"ogbg-molbace\" # ogbg-molhiv\n",
    "cfg.llm.template = \"CorrFS-5\"\n",
    "cfg.llm.model.name = \"gpt-3.5-turbo-1106\"\n",
    "cfg.demo_test = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:29:18.615290Z",
     "start_time": "2024-01-08T19:29:18.594673Z"
    }
   },
   "id": "543163ce12566ec0"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# RPM limit (adjust according to your plan)\n",
    "rpm_limit = 500 if cfg.demo_test else 3500\n",
    "# TPM limit (adjust according to your plan)\n",
    "tpm_limit = 1000 if cfg.demo_test else 60000\n",
    "\n",
    "# Set up OpenAI API\n",
    "client = openai.OpenAI(api_key=cfg.OPENAI_API_KEY)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:29:18.647878Z",
     "start_time": "2024-01-08T19:29:18.614953Z"
    }
   },
   "id": "92a1a43f56b63f5c"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:29:18.648247Z",
     "start_time": "2024-01-08T19:29:18.647829Z"
    }
   },
   "id": "f0a3bbc28338357d"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "dataloader = DatasetLoader(name=cfg.dataset, text='raw')\n",
    "dataset, smiles = dataloader.dataset, dataloader.text\n",
    "message_list = load_message(\n",
    "    dataset_name=cfg.dataset, message_type=cfg.llm.template, \n",
    "    demo_test=cfg.demo_test\n",
    ")\n",
    "if cfg.demo_test:\n",
    "    message_list = message_list[:cfg.num_sample]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:29:18.661468Z",
     "start_time": "2024-01-08T19:29:18.647927Z"
    }
   },
   "id": "a0494bbd1c5f28e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:29:18.661904Z",
     "start_time": "2024-01-08T19:29:18.661417Z"
    }
   },
   "id": "dc122acf26bfbcbc",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'role': 'system',\n  'content': 'You are an expert in Graph Machine Learning, specializing in correcting predictions made by Graph Neural Networks (GNNs). The prediction is about whether the molecule inhibits human β-secretase 1(BACE-1).'},\n {'role': 'user',\n  'content': \"The molecule's SMILES string is Clc1ccc(nc1)C(=O)Nc1cc(C2(N=C(N)c3c(C2)cccc3)C)c(F)cc1, and its prediction given by the GNN model is False with predicted probability 0.8050. Provide corrected prediction. \"},\n {'role': 'assistant', 'content': 'True.'},\n {'role': 'user',\n  'content': \"The molecule's SMILES string is Fc1cc(cc(F)c1)CC(NC(=O)C(N1CCC(NC(=O)C)(CC2CC2)C1=O)C)C(O)C[NH2+]Cc1cc(OC)ccc1, and its prediction given by the GNN model is True with predicted probability 0.5800. Provide corrected prediction. \"},\n {'role': 'assistant', 'content': 'True.'},\n {'role': 'user',\n  'content': \"The molecule's SMILES string is S1(=O)(=O)N(c2cc(cc3c2n(cc3CC)CC1)C(=O)N[C@H]([C@H](O)C[NH2+]C1CCOCC1)Cc1ccccc1)CC, and its prediction given by the GNN model is True with predicted probability 0.7394. Provide corrected prediction. \"},\n {'role': 'assistant', 'content': 'True.'},\n {'role': 'user',\n  'content': \"The molecule's SMILES string is Clc1cnc(nc1)C(=O)Nc1cc(C2(N=C(OCC2(F)F)N)C)c(F)cc1, and its prediction given by the GNN model is True with predicted probability 0.5563. Provide corrected prediction. \"},\n {'role': 'assistant', 'content': 'True.'},\n {'role': 'user',\n  'content': \"The molecule's SMILES string is S1(=O)(=O)CC(Cc2cc(OC3COC3)c(N)c(F)c2)C(O)C([NH2+]Cc2cc(ccc2)C(C)(C)C)C1, and its prediction given by the GNN model is True with predicted probability 0.7592. Provide corrected prediction. \"},\n {'role': 'assistant', 'content': 'True.'},\n {'role': 'user',\n  'content': \"The molecule's SMILES string is O1CC[C@@H](NC(=O)[C@@H](Cc2cc3cc(ccc3nc2N)-c2ccccc2C)C)CC1(C)C, and its prediction given by the GNN model is False with predicted probability 0.9243. Provide corrected prediction. Answer this question in the form: Prediction: <True or False>; Possibility: <number>.\"}]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_list[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:29:18.800125Z",
     "start_time": "2024-01-08T19:29:18.665913Z"
    }
   },
   "id": "b39068f0144526d",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:29:18.800650Z",
     "start_time": "2024-01-08T19:29:18.800101Z"
    }
   },
   "id": "46834b041feeab7b"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query ogbg-molbace gpt-3.5-turbo-1106:  10%|█         | 2/20 [00:03<00:30,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory /home/zhiqiang/LLMaGML/output/chat_completion/ogbg-molbace/cache_chat_completion/CorrFS-5/\n",
      "Created directory /home/zhiqiang/LLMaGML/output/response/ogbg-molbace/cache_response/CorrFS-5/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query ogbg-molbace gpt-3.5-turbo-1106: 100%|██████████| 20/20 [00:41<00:00,  2.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# Save all queries\n",
    "chat_completion_list = []\n",
    "response_list = []\n",
    "\n",
    "# Run batch queries\n",
    "batch_message_list = []\n",
    "batch_message_token_num = 0\n",
    "batch_start_id = 0\n",
    "batch_end_id = 0\n",
    "display = \"Query {} {}\".format(cfg.dataset, cfg.llm.model.name)\n",
    "for message_id, message in enumerate(tqdm(message_list, desc=display)):\n",
    "    \n",
    "    batch_message_token_num += num_tokens_from_messages(\n",
    "        messages=message, original_model=cfg.llm.model.name\n",
    "    )\n",
    "    \n",
    "    if (batch_message_token_num >= tpm_limit) and (message_id < len(message_list) - 1):\n",
    "        \n",
    "        batch_chat_completion_list, batch_response_list = query_chatgpt_batch(\n",
    "            client=client, dataset_name=cfg.dataset,\n",
    "            llm_model=cfg.llm.model.name, template=cfg.llm.template,\n",
    "            batch_message_list=batch_message_list, batch_start_id=batch_start_id,\n",
    "            rpm_limit=rpm_limit\n",
    "        )\n",
    "        chat_completion_list += batch_chat_completion_list\n",
    "        response_list += batch_response_list\n",
    "        batch_message_list = [message]\n",
    "        batch_message_token_num = num_tokens_from_messages(\n",
    "            messages=message, original_model=cfg.llm.model.name\n",
    "        )\n",
    "        batch_start_id = message_id\n",
    "    elif message_id == len(message_list) - 1:\n",
    "        batch_message_list.append(message)\n",
    "        \n",
    "        batch_chat_completion_list, batch_response_list = query_chatgpt_batch(\n",
    "            client=client, dataset_name=cfg.dataset,\n",
    "            llm_model=cfg.llm.model.name, template=cfg.llm.template,\n",
    "            batch_message_list=batch_message_list, batch_start_id=batch_start_id,\n",
    "            rpm_limit=rpm_limit\n",
    "        )\n",
    "        chat_completion_list += batch_chat_completion_list\n",
    "        response_list += batch_response_list\n",
    "    else:\n",
    "        batch_message_list.append(message)\n",
    "        batch_end_id += 1\n",
    "\n",
    "# Save all responses\n",
    "save_chatcompletion(\n",
    "    dataset_name=cfg.dataset, chat_completion=chat_completion_list,\n",
    "    template=cfg.llm.template, demo_test=cfg.demo_test\n",
    ")\n",
    "# Save all responses\n",
    "save_response(\n",
    "    dataset_name=cfg.dataset, list_response=response_list,\n",
    "    template=cfg.llm.template, demo_test=cfg.demo_test\n",
    ")\n",
    "# Clean all cache files\n",
    "clean_cache_chat_completion_response(\n",
    "    dataset_name=cfg.dataset, template=cfg.llm.template\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:30:00.489209Z",
     "start_time": "2024-01-08T19:29:18.800186Z"
    }
   },
   "id": "2c2b3a87ee103c0f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'Prediction: True; Possibility: 0.9243'"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_list[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T19:30:00.491951Z",
     "start_time": "2024-01-08T19:30:00.489111Z"
    }
   },
   "id": "8b4e0e2ff834b72e",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "67b7dea03f61602f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
